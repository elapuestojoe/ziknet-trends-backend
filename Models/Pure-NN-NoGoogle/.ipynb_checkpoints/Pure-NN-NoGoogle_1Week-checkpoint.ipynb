{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from keras import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Dense, Concatenate, Flatten, Input, GRU\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.optimizers import Adam, RMSprop, Adadelta\n",
    "from keras.constraints import non_neg\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "\n",
    "# USE CPU\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Population values\n",
    "population = {\n",
    "    \"Chiapas_2016-2017.csv\": 5217908,\n",
    "    \"Colima_2016-2017.csv\": 711235,\n",
    "    \"Guerrero_2016-2017.csv\": 3533251,\n",
    "    \"Hidalgo_2016-2017.csv\": 2858359,\n",
    "    \"NuevoLeon_2016-2017.csv\": 5119504,\n",
    "    \"Oaxaca_2016-2017.csv\": 3967889,\n",
    "    \"QuintanaRoo_2016-2017.csv\": 1501562,\n",
    "    \"Tabasco_2016-2017.csv\" : 2395272,\n",
    "    \"Veracruz_2016-2017.csv\" : 8112505,\n",
    "    \"Yucatan_2016-2017.csv\" : 2097175,\n",
    "    \n",
    "    \"casanare_2016-2017.csv\" : 356438,\n",
    "    \"cordoba_2016-2017.csv\" : 1709603,\n",
    "    \"cundinamarca_2016-2017.csv\" : 2680041,\n",
    "    \"huila_2016-2017.csv\" : 1154804,\n",
    "    \"meta_2016-2017.csv\" : 961292,\n",
    "    \"santander_2016-2017.csv\" : 2061095,\n",
    "    \"santander_norte_2016-2017.csv\" : 1355723,\n",
    "    \"tolima_2016-2017.csv\" : 1408274,\n",
    "    \"valle_cauca_2016-2017.csv\" : 4613377,\n",
    "    \n",
    "    \"Alagoas_2016-2017.csv\": 3375823,\n",
    "    \"Bahia_2016-2017.csv\": 15344447,\n",
    "    \"Ceara_2016-2017.csv\": 9020460,\n",
    "    \"Goias_2016-2017.csv\": 6778772,\n",
    "    \"Maranhao_2016-2017.csv\": 7000229,\n",
    "    \"MatoGrosso_2016-2017.csv\": 3344544,\n",
    "    \"MinasGerais_2016-2017.csv\": 21119536,\n",
    "    \"Para_2016-2017.csv\": 8366628,\n",
    "    \"RioDeJaneiro_2016-2017.csv\": 16718956,\n",
    "    \"SaoPaulo_2016-2017.csv\": 45094866,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createModel(modelName):\n",
    "    jsonName = \"{}.json\".format(modelName)\n",
    "    h5Name = \"{}.h5\".format(modelName)\n",
    "    \n",
    "    \n",
    "    input_layer = Input(shape=(4,2))\n",
    "    b1_out = Dense(64)(input_layer)\n",
    "    b1_out = Flatten()(b1_out)\n",
    "    \n",
    "    b2_out = Dense(32, activation=\"relu\", kernel_regularizer=\"l2\")(input_layer)\n",
    "    b2_out = Flatten()(b2_out)\n",
    "    \n",
    "    concatenated = concatenate([b1_out, b2_out])\n",
    "    out = Dense(4, activation=\"relu\", kernel_regularizer=\"l2\")(concatenated)\n",
    "    out = Dense(4, activation=\"relu\", kernel_regularizer=\"l2\")(out)\n",
    "    out = Dense(1, activation=\"linear\", kernel_constraint=non_neg(), name='output_layer')(out)\n",
    "    \n",
    "    model = Model([input_layer], out)\n",
    "    model.compile(loss=[\"mae\"], optimizer=\"adam\", metrics=[\"mae\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getXY(dataset, scale):\n",
    "#     dataset[[\"Searches\"]] /= 100\n",
    "    dataset[[\"Cases\"]] = dataset[[\"Cases\"]].apply(lambda x: x*100000/scale, axis=1)\n",
    "\n",
    "    values = dataset[[\"Cases\"]].values.astype(\"float32\")\n",
    "    \n",
    "    n_weeks = 4\n",
    "    n_features = 2\n",
    "\n",
    "    reframed = series_to_supervised(values, n_weeks, 1)\n",
    "    values = reframed.values\n",
    "    print(reframed.columns)\n",
    "    \n",
    "    print(\"Reframed Shape: \", reframed.shape)\n",
    "    totalFeatures = reframed.shape[1]\n",
    "    n_obs = n_weeks * n_features\n",
    "\n",
    "    x,y = values[:, :8], values[:, -1] # Pick 4 previous weeks and predict 4 week ahead \n",
    "\n",
    "    x = x.reshape((x.shape[0], n_weeks, n_features)) # Reshape as 3-D\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "country = input(\"Country: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "countries = [\"Mexico\", \"Colombia\", \"Brazil\"]\n",
    "otherCountries = [x for x in countries if x != country]\n",
    "\n",
    "model = createModel(country)\n",
    "#Train\n",
    "folder = \"../../data/{}/processed_data\".format(country)\n",
    "files = os.listdir(folder)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for file in getSortedFiles(folder, files):\n",
    "        dataset = pd.read_csv(\"{}/{}\".format(folder, file), index_col=0)\n",
    "        state = file\n",
    "        print(file)\n",
    "        x, y = getXY(dataset, population[file])\n",
    "        \n",
    "        print(x, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
