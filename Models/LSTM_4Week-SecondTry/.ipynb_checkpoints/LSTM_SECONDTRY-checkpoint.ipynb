{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from keras import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Dense, Concatenate, Flatten, Input\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import logcosh\n",
    "import tensorflow as tf\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Population values\n",
    "population = {\n",
    "    \"Chiapas_2016-2017.csv\": 5217908,\n",
    "    \"Colima_2016-2017.csv\": 711235,\n",
    "    \"Guerrero_2016-2017.csv\": 3533251,\n",
    "    \"Hidalgo_2016-2017.csv\": 2858359,\n",
    "    \"NuevoLeon_2016-2017.csv\": 5119504,\n",
    "    \"Oaxaca_2016-2017.csv\": 3967889,\n",
    "    \"QuintanaRoo_2016-2017.csv\": 1501562,\n",
    "    \"Tabasco_2016-2017.csv\" : 2395272,\n",
    "    \"Veracruz_2016-2017.csv\" : 8112505,\n",
    "    \"Yucatan_2016-2017.csv\" : 2097175,\n",
    "    \n",
    "    \"casanare_2016-2017.csv\" : 356438,\n",
    "    \"cordoba_2016-2017.csv\" : 1709603,\n",
    "    \"cundinamarca_2016-2017.csv\" : 2680041,\n",
    "    \"huila_2016-2017.csv\" : 1154804,\n",
    "    \"meta_2016-2017.csv\" : 961292,\n",
    "    \"santander_2016-2017.csv\" : 2061095,\n",
    "    \"santander_norte_2016-2017.csv\" : 1355723,\n",
    "    \"tolima_2016-2017.csv\" : 1408274,\n",
    "    \"valle_cauca_2016-2017.csv\" : 4613377,\n",
    "    \n",
    "    \"Alagoas_2016-2017.csv\": 3375823,\n",
    "    \"Bahia_2016-2017.csv\": 15344447,\n",
    "    \"Ceara_2016-2017.csv\": 9020460,\n",
    "    \"Goias_2016-2017.csv\": 6778772,\n",
    "    \"Maranhao_2016-2017.csv\": 7000229,\n",
    "    \"MatoGrosso_2016-2017.csv\": 3344544,\n",
    "    \"MinasGerais_2016-2017.csv\": 21119536,\n",
    "    \"Para_2016-2017.csv\": 8366628,\n",
    "    \"RioDeJaneiro_2016-2017.csv\": 16718956,\n",
    "    \"SaoPaulo_2016-2017.csv\": 45094866,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def saveModel(model, modelName):\n",
    "    jsonName = \"{}.json\".format(modelName)\n",
    "    h5Name = \"{}.h5\".format(modelName)\n",
    "\n",
    "    model_json = model.to_json()\n",
    "    with open(jsonName, \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    #seralize weights to HDF5\n",
    "    model.save_weights(h5Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createModel(modelName):\n",
    "    jsonName = \"{}.json\".format(modelName)\n",
    "    h5Name = \"{}.h5\".format(modelName)\n",
    "    \n",
    "    \n",
    "    input_layer = Input(shape=(4,2))\n",
    "    b1_out = LSTM(256, activation=\"relu\", return_sequences=True)(input_layer)\n",
    "#     b1_out = LSTM(512, activation=\"tanh\", return_sequences=False)(b1_out)\n",
    "    b1_out = LSTM(128, activation=\"relu\", return_sequences=False)(b1_out)\n",
    "    \n",
    "    model1 = Model(input_layer, b1_out)\n",
    "    \n",
    "    b2_out = Dense(256, activation=\"relu\")(input_layer)\n",
    "    b2_out = Dense(128, activation=\"tanh\")(b2_out)\n",
    "    b2_out = Flatten()(b2_out)\n",
    "    \n",
    "    model2 = Model(input_layer, b2_out)\n",
    "    \n",
    "    concatenated = concatenate([b1_out, b2_out])\n",
    "    out = Dense(256, activation=\"relu\")(concatenated)\n",
    "    out = Dense(4, activation='linear', name='output_layer')(concatenated)\n",
    "    \n",
    "    model = Model([input_layer], out)\n",
    "    model.compile(loss=[logcosh], optimizer=\"adam\", metrics=[\"mae\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getXY(dataset, scale):\n",
    "    dataset[[\"Searches\"]] /= 100\n",
    "    dataset[[\"Cases\"]] = dataset[[\"Cases\"]].apply(lambda x: x*100000/scale, axis=1)\n",
    "\n",
    "    values = dataset.values.astype(\"float32\")\n",
    "    \n",
    "    n_weeks = 4\n",
    "    n_features = 3\n",
    "\n",
    "    reframed = series_to_supervised(values, n_weeks, 4)\n",
    "    values = reframed.values\n",
    "    print(reframed.columns)\n",
    "    \n",
    "    print(\"Reframed Shape: \", reframed.shape)\n",
    "    totalFeatures = reframed.shape[1]\n",
    "    n_obs = n_weeks * n_features\n",
    "\n",
    "    x,y = values[:, :12], values[:, 14::3] # Pick 4 previous weeks and predict 4 next \n",
    "\n",
    "    x = x.reshape((x.shape[0], n_weeks, n_features)) # Reshape as 3-D\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def formatFilename(filename):\n",
    "    return filename.replace(\".csv\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: Mexico\n"
     ]
    }
   ],
   "source": [
    "country = input(\"Country: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chiapas_2016-2017.csv\n",
      "Index(['var1(t-4)', 'var2(t-4)', 'var1(t-3)', 'var2(t-3)', 'var1(t-2)',\n",
      "       'var2(t-2)', 'var1(t-1)', 'var2(t-1)', 'var1(t)', 'var2(t)',\n",
      "       'var1(t+1)', 'var2(t+1)', 'var1(t+2)', 'var2(t+2)', 'var1(t+3)',\n",
      "       'var2(t+3)'],\n",
      "      dtype='object')\n",
      "Reframed Shape:  (97, 16)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected output_layer to have shape (4,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-f48d86d56729>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m                 \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m                  )\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0motherCountry\u001b[0m \u001b[1;32min\u001b[0m \u001b[0motherCountries\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Aplicaciones\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    953\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 955\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    956\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Aplicaciones\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    790\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 792\u001b[1;33m                 exception_prefix='target')\n\u001b[0m\u001b[0;32m    793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m             \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Aplicaciones\\Anaconda\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    134\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    137\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected output_layer to have shape (4,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "np.random.seed(2018)\n",
    "\n",
    "countries = [\"Mexico\", \"Colombia\", \"Brazil\"]\n",
    "otherCountries = [x for x in countries if x != country]\n",
    "\n",
    "model = createModel(country)\n",
    "#Train\n",
    "folder = \"../../data/{}/processed_data\".format(country)\n",
    "files = os.listdir(folder)\n",
    "with tf.Session() as sess:\n",
    "    for file in files:\n",
    "        dataset = pd.read_csv(\"{}/{}\".format(folder, file), index_col=0)\n",
    "        state = file\n",
    "        print(file)\n",
    "        x, y = getXY(dataset, population[file])\n",
    "        model.fit(x, y,\n",
    "                epochs = 100,\n",
    "                batch_size=x.shape[0],\n",
    "                verbose=0, \n",
    "                shuffle=False\n",
    "                 )\n",
    "    for otherCountry in otherCountries:\n",
    "        otherFolder = \"../../data/{}/processed_data\".format(otherCountry)\n",
    "        testFiles = os.listdir(otherFolder)\n",
    "\n",
    "        for file in testFiles:\n",
    "\n",
    "                test_dataset = pd.read_csv(\"{}/{}\".format(otherFolder, file), index_col=0)\n",
    "                 #Calculate Naive \n",
    "                    \n",
    "                naive1Week = test_dataset[\"Cases\"].values[3:-4]\n",
    "                naive2Week = test_dataset[\"Cases\"].values[2:-5]\n",
    "                naive3Week = test_dataset[\"Cases\"].values[1:-6]\n",
    "                naive4Week = test_dataset[\"Cases\"].values[0:-7]\n",
    "                \n",
    "                state = file\n",
    "                if(not os.path.isdir(\"{}/{}\".format(country, otherCountry))):\n",
    "                    os.mkdir(\"{}/{}\".format(country, otherCountry))\n",
    "                \n",
    "                if(not os.path.isdir(\"{}/{}/{}\".format(country, otherCountry, file))):\n",
    "                    os.mkdir(\"{}/{}/{}\".format(country, otherCountry, file))\n",
    "                    \n",
    "                outFolder = \"{}/{}/{}\".format(country, otherCountry, file)\n",
    "                \n",
    "                formattedFilename = formatFilename(file)\n",
    "                \n",
    "                test_x, test_y = getXY(test_dataset, population[file])\n",
    "                predictions = model.predict(test_x)\n",
    "                \n",
    "                errors = test_y - predictions\n",
    "                \n",
    "                #Transform to 1-D\n",
    "                test_y = test_y.reshape((len(test_y), 4))\n",
    "                \n",
    "                #Rescale\n",
    "                inv_yPred = np.apply_along_axis(lambda x: x * population[file] / 100000, 1, predictions)\n",
    "#                 inv_y = np.apply_along_axis(lambda x: x * population[file] / 100000, 1, test_y)\n",
    "                \n",
    "                \n",
    "                test_dataset = test_dataset[4:-3]\n",
    "                test_dataset[\"Cases\"] *= (population[file] / 100000)\n",
    "                test_dataset[\"Week1-Prediction\"] = inv_yPred[:,0]\n",
    "                test_dataset[\"Week2-Prediction\"] = inv_yPred[:,1]\n",
    "                test_dataset[\"Week3-Prediction\"] = inv_yPred[:,2]\n",
    "                test_dataset[\"Week4-Prediction\"] = inv_yPred[:,3]\n",
    "                \n",
    "                #Set naive\n",
    "                test_dataset[\"Naive-1Week\"] = naive1Week\n",
    "                test_dataset[\"Naive-2Week\"] = naive2Week\n",
    "                test_dataset[\"Naive-3Week\"] = naive3Week\n",
    "                test_dataset[\"Naive-4Week\"] = naive4Week\n",
    "                #\n",
    "                \n",
    "                test_dataset[\"Week2-Prediction\"] = test_dataset[\"Week2-Prediction\"].shift(1)\n",
    "                test_dataset[\"Week3-Prediction\"] = test_dataset[\"Week3-Prediction\"].shift(2)\n",
    "                test_dataset[\"Week4-Prediction\"] = test_dataset[\"Week4-Prediction\"].shift(3)\n",
    "                \n",
    "                test_dataset.dropna(inplace=True)\n",
    "                \n",
    "                test_dataset[\"Week1-Error\"] = test_dataset[\"Week1-Prediction\"] - test_dataset[\"Cases\"]\n",
    "                test_dataset[\"Week2-Error\"] = test_dataset[\"Week2-Prediction\"] - test_dataset[\"Cases\"]\n",
    "                test_dataset[\"Week3-Error\"] = test_dataset[\"Week3-Prediction\"] - test_dataset[\"Cases\"]\n",
    "                test_dataset[\"Week4-Error\"] = test_dataset[\"Week4-Prediction\"] - test_dataset[\"Cases\"]\n",
    "                \n",
    "                test_dataset.to_csv(\"{}/{}\".format(outFolder, file))\n",
    "\n",
    "                \n",
    "                #Plot each week vs cases\n",
    "                \n",
    "                #Week 1\n",
    "                colors = ['#2962FF', '#F44336']\n",
    "                test_dataset[[\"Cases\", \"Week1-Prediction\"]].plot(figsize=(10,10), color=colors)\n",
    "                ax = plt.gca()\n",
    "                ax.set_facecolor((0.9, 0.9, 0.9, 0.7))\n",
    "                plt.title(\"LSTM Model -{}\\n1 Week ahead prediction vs. Observed ZIKV cases\".format(formattedFilename))\n",
    "                plt.xlabel(\"Week\")\n",
    "                plt.ylabel(\"ZIKV Cases\")\n",
    "                plt.legend()\n",
    "                plt.grid()\n",
    "                fig = plt.gcf()\n",
    "                fig.savefig(\"{}/1-Week-{}.png\".format(outFolder, formattedFilename))\n",
    "                plt.close(\"all\")\n",
    "                plt.clf()\n",
    "                \n",
    "                \n",
    "                #Week 2\n",
    "                colors = ['#2962FF', '#D500F9']\n",
    "                test_dataset[[\"Cases\", \"Week2-Prediction\"]].plot(figsize=(10,10), color=colors)\n",
    "                ax = plt.gca()\n",
    "                ax.set_facecolor((0.9, 0.9, 0.9, 0.7))\n",
    "                plt.title(\"LSTM Model -{}\\n2 Weeks ahead prediction vs. Observed ZIKV cases\".format(formattedFilename))\n",
    "                plt.xlabel(\"Week\")\n",
    "                plt.ylabel(\"ZIKV Cases\")\n",
    "                plt.legend()\n",
    "                plt.grid(linestyle='dashed', linewidth=1.5)\n",
    "                fig = plt.gcf()\n",
    "                fig.savefig(\"{}/2-Week-{}.png\".format(outFolder, formattedFilename))\n",
    "                plt.close(\"all\")\n",
    "                plt.clf()\n",
    "\n",
    "                #Week 3\n",
    "                colors = ['#2962FF', '#09af00']\n",
    "                test_dataset[[\"Cases\", \"Week3-Prediction\"]].plot(figsize=(10,10), color=colors)\n",
    "                ax = plt.gca()\n",
    "                ax.set_facecolor((0.9, 0.9, 0.9, 0.7))\n",
    "                plt.title(\"LSTM Model -{}\\n3 Weeks ahead prediction vs. Observed ZIKV cases\".format(formattedFilename))\n",
    "                plt.xlabel(\"Week\")\n",
    "                plt.ylabel(\"ZIKV Cases\")\n",
    "                plt.legend()\n",
    "                plt.grid(linestyle='dashed', linewidth=1.5)\n",
    "                fig = plt.gcf()\n",
    "                fig.savefig(\"{}/3-Week-{}.png\".format(outFolder, formattedFilename))\n",
    "                plt.close(\"all\")\n",
    "                plt.clf()\n",
    "                \n",
    "                #Week 4\n",
    "                colors = ['#2962FF', '#212121']\n",
    "                test_dataset[[\"Cases\", \"Week4-Prediction\"]].plot(figsize=(10,10), color=colors)\n",
    "                ax = plt.gca()\n",
    "                ax.set_facecolor((0.9, 0.9, 0.9, 0.7))\n",
    "                plt.title(\"LSTM Model -{}\\n4 Weeks ahead prediction vs. Observed ZIKV cases\".format(formattedFilename))\n",
    "                plt.xlabel(\"Week\")\n",
    "                plt.ylabel(\"ZIKV Cases\")\n",
    "                plt.legend()\n",
    "                plt.grid(linestyle='dashed', linewidth=1.5)\n",
    "                fig = plt.gcf()\n",
    "                fig.savefig(\"{}/4-Week-{}.png\".format(outFolder, formattedFilename))\n",
    "                plt.close(\"all\")\n",
    "                plt.clf()\n",
    "                \n",
    "                #All\n",
    "                colors = ['#2962FF', '#F44336', \"#D500F9\", \"#09af00\", \"#212121\"]\n",
    "                test_dataset[[\"Cases\", \"Week1-Prediction\",\n",
    "                              \"Week2-Prediction\",\n",
    "                              \"Week3-Prediction\",\n",
    "                             \"Week4-Prediction\"]].plot(figsize=(10,10), color=colors)\n",
    "                ax = plt.gca()\n",
    "                ax.set_facecolor((0.9, 0.9, 0.9, 0.7))\n",
    "                plt.title(\"LSTM Model -{}\\n1-4 Weeks ahead prediction vs. Observed ZIKV cases\".format(formattedFilename))\n",
    "                plt.xlabel(\"Week\")\n",
    "                plt.ylabel(\"ZIKV Cases\")\n",
    "                plt.legend()\n",
    "                plt.grid(linestyle='dashed', linewidth=1.5)\n",
    "                fig = plt.gcf()\n",
    "                fig.savefig(\"{}/All-{}.png\".format(outFolder, formattedFilename))\n",
    "                plt.close(\"all\")\n",
    "                plt.clf()\n",
    "                \n",
    "                #Compare with Naive\n",
    "                #Week 1\n",
    "                colors = ['#2962FF', '#09af00', \"#212121\"]\n",
    "                test_dataset[[\"Cases\", \"Week1-Prediction\", \"Naive-1Week\"]].plot(figsize=(10,10), color=colors)\n",
    "                ax = plt.gca()\n",
    "                ax.set_facecolor((0.9, 0.9, 0.9, 0.7))\n",
    "                plt.title(\"LSTM Model -{}\\n1 Weeks ahead prediction vs. Observed ZIKV cases vs. Naive\".format(formattedFilename))\n",
    "                plt.xlabel(\"Week\")\n",
    "                plt.ylabel(\"ZIKV Cases\")\n",
    "                plt.legend()\n",
    "                plt.grid(linestyle='dashed', linewidth=1.5)\n",
    "                fig = plt.gcf()\n",
    "                fig.savefig(\"{}/Naive-1-Week-{}.png\".format(outFolder, formattedFilename))\n",
    "                plt.close(\"all\")\n",
    "                plt.clf()\n",
    "                \n",
    "                #Week 2\n",
    "                colors = ['#2962FF', '#09af00', \"#212121\"]\n",
    "                test_dataset[[\"Cases\", \"Week2-Prediction\", \"Naive-2Week\"]].plot(figsize=(10,10), color=colors)\n",
    "                ax = plt.gca()\n",
    "                ax.set_facecolor((0.9, 0.9, 0.9, 0.7))\n",
    "                plt.title(\"LSTM Model -{}\\n1 Weeks ahead prediction vs. Observed ZIKV cases vs. Naive\".format(formattedFilename))\n",
    "                plt.xlabel(\"Week\")\n",
    "                plt.ylabel(\"ZIKV Cases\")\n",
    "                plt.legend()\n",
    "                plt.grid(linestyle='dashed', linewidth=1.5)\n",
    "                fig = plt.gcf()\n",
    "                fig.savefig(\"{}/Naive-2-Week-{}.png\".format(outFolder, formattedFilename))\n",
    "                plt.close(\"all\")\n",
    "                plt.clf()\n",
    "                \n",
    "                #Week 3\n",
    "                colors = ['#2962FF', '#09af00', \"#212121\"]\n",
    "                test_dataset[[\"Cases\", \"Week3-Prediction\", \"Naive-3Week\"]].plot(figsize=(10,10), color=colors)\n",
    "                ax = plt.gca()\n",
    "                ax.set_facecolor((0.9, 0.9, 0.9, 0.7))\n",
    "                plt.title(\"LSTM Model -{}\\n1 Weeks ahead prediction vs. Observed ZIKV cases vs. Naive\".format(formattedFilename))\n",
    "                plt.xlabel(\"Week\")\n",
    "                plt.ylabel(\"ZIKV Cases\")\n",
    "                plt.legend()\n",
    "                plt.grid(linestyle='dashed', linewidth=1.5)\n",
    "                fig = plt.gcf()\n",
    "                fig.savefig(\"{}/Naive-3-Week-{}.png\".format(outFolder, formattedFilename))\n",
    "                plt.close(\"all\")\n",
    "                plt.clf()\n",
    "                \n",
    "                #Week 4\n",
    "                colors = ['#2962FF', '#09af00', \"#212121\"]\n",
    "                test_dataset[[\"Cases\", \"Week4-Prediction\", \"Naive-4Week\"]].plot(figsize=(10,10), color=colors)\n",
    "                ax = plt.gca()\n",
    "                ax.set_facecolor((0.9, 0.9, 0.9, 0.7))\n",
    "                plt.title(\"LSTM Model -{}\\n1 Weeks ahead prediction vs. Observed ZIKV cases vs. Naive\".format(formattedFilename))\n",
    "                plt.xlabel(\"Week\")\n",
    "                plt.ylabel(\"ZIKV Cases\")\n",
    "                plt.legend()\n",
    "                plt.grid(linestyle='dashed', linewidth=1.5)\n",
    "                fig = plt.gcf()\n",
    "                fig.savefig(\"{}/Naive-4-Week-{}.png\".format(outFolder, formattedFilename))\n",
    "                plt.close(\"all\")\n",
    "                plt.clf()\n",
    "                \n",
    "                \n",
    "                \n",
    "    saveModel(model, \"{}/Model\".format(country))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
