{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from keras import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Dense, Concatenate, Flatten, Input\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import logcosh\n",
    "import tensorflow as tf\n",
    "from keras.constraints import non_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Population values\n",
    "population = {\n",
    "    \"Chiapas_2016-2017.csv\": 5217908,\n",
    "    \"Colima_2016-2017.csv\": 711235,\n",
    "    \"Guerrero_2016-2017.csv\": 3533251,\n",
    "    \"Hidalgo_2016-2017.csv\": 2858359,\n",
    "    \"NuevoLeon_2016-2017.csv\": 5119504,\n",
    "    \"Oaxaca_2016-2017.csv\": 3967889,\n",
    "    \"QuintanaRoo_2016-2017.csv\": 1501562,\n",
    "    \"Tabasco_2016-2017.csv\" : 2395272,\n",
    "    \"Veracruz_2016-2017.csv\" : 8112505,\n",
    "    \"Yucatan_2016-2017.csv\" : 2097175,\n",
    "    \n",
    "    \"casanare_2016-2017.csv\" : 356438,\n",
    "    \"cordoba_2016-2017.csv\" : 1709603,\n",
    "    \"cundinamarca_2016-2017.csv\" : 2680041,\n",
    "    \"huila_2016-2017.csv\" : 1154804,\n",
    "    \"meta_2016-2017.csv\" : 961292,\n",
    "    \"santander_2016-2017.csv\" : 2061095,\n",
    "    \"santander_norte_2016-2017.csv\" : 1355723,\n",
    "    \"tolima_2016-2017.csv\" : 1408274,\n",
    "    \"valle_cauca_2016-2017.csv\" : 4613377,\n",
    "    \n",
    "    \"Alagoas_2016-2017.csv\": 3375823,\n",
    "    \"Bahia_2016-2017.csv\": 15344447,\n",
    "    \"Ceara_2016-2017.csv\": 9020460,\n",
    "    \"Goias_2016-2017.csv\": 6778772,\n",
    "    \"Maranhao_2016-2017.csv\": 7000229,\n",
    "    \"MatoGrosso_2016-2017.csv\": 3344544,\n",
    "    \"MinasGerais_2016-2017.csv\": 21119536,\n",
    "    \"Para_2016-2017.csv\": 8366628,\n",
    "    \"RioDeJaneiro_2016-2017.csv\": 16718956,\n",
    "    \"SaoPaulo_2016-2017.csv\": 45094866,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getXY(dataset, scale):\n",
    "    dataset[[\"Searches\"]] /= 100\n",
    "    dataset[[\"Cases\"]] = dataset[[\"Cases\"]].apply(lambda x: x*100000/scale, axis=1)\n",
    "    \n",
    "    values = dataset.values.astype(\"float32\")\n",
    "    \n",
    "    n_weeks = 4\n",
    "    n_features = 2\n",
    "\n",
    "    reframed = series_to_supervised(values, n_weeks, 1)\n",
    "    values = reframed.values\n",
    "    print(\"Reframed Shape: \", reframed.shape)\n",
    "    totalFeatures = reframed.shape[1]\n",
    "    n_obs = n_weeks * n_features\n",
    "\n",
    "    x,y = values[:, :8], values[:, -1] # Pick 4 previous weeks and predict 4 week ahead \n",
    "\n",
    "    x = x.reshape((x.shape[0], n_weeks, n_features)) # Reshape as 3-D\n",
    "    return x, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def saveModel(model, modelName):\n",
    "    jsonName = \"{}.json\".format(modelName)\n",
    "    h5Name = \"{}.h5\".format(modelName)\n",
    "\n",
    "    model_json = model.to_json()\n",
    "    with open(jsonName, \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    #seralize weights to HDF5\n",
    "    model.save_weights(h5Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createModel(modelName):\n",
    "    jsonName = \"{}.json\".format(modelName)\n",
    "    h5Name = \"{}.h5\".format(modelName)\n",
    "    \n",
    "    \n",
    "    input_layer = Input(shape=(4,2))\n",
    "    b1_out = LSTM(128, return_sequences=False)(input_layer)\n",
    "    \n",
    "    b2_out = Dense(128, activation=\"relu\")(input_layer)\n",
    "    b2_out = Flatten()(b2_out)\n",
    "    \n",
    "    concatenated = concatenate([b1_out, b2_out])\n",
    "    out = Dense(4, activation=\"relu\")(concatenated)\n",
    "    out = Dense(1, activation=\"linear\", kernel_constraint=non_neg(), name='output_layer')(out)\n",
    "    \n",
    "    model = Model([input_layer], out)\n",
    "    model.compile(loss=[\"mae\"], optimizer=\"adam\", metrics=[\"mae\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def formatFilename(filename):\n",
    "    return filename.replace(\".csv\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Aplicaciones\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:2352: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reframed Shape:  (48, 10)\n",
      "Reframed Shape:  (52, 10)\n",
      "Reframed Shape:  (48, 10)\n",
      "Reframed Shape:  (52, 10)\n",
      "Reframed Shape:  (48, 10)\n",
      "Reframed Shape:  (52, 10)\n",
      "Reframed Shape:  (48, 10)\n",
      "Reframed Shape:  (52, 10)\n",
      "Reframed Shape:  (48, 10)\n",
      "Reframed Shape:  (52, 10)\n",
      "Reframed Shape:  (48, 10)\n",
      "Reframed Shape:  (52, 10)\n",
      "Reframed Shape:  (48, 10)\n",
      "Reframed Shape:  (52, 10)\n",
      "Reframed Shape:  (48, 10)\n",
      "Reframed Shape:  (52, 10)\n",
      "Reframed Shape:  (48, 10)\n",
      "Reframed Shape:  (52, 10)\n",
      "Reframed Shape:  (48, 10)\n",
      "Reframed Shape:  (52, 10)\n",
      "Reframed Shape:  (48, 10)\n",
      "Reframed Shape:  (52, 10)\n",
      "Reframed Shape:  (48, 10)\n",
      "Reframed Shape:  (52, 10)\n",
      "Reframed Shape:  (48, 10)\n",
      "Reframed Shape:  (52, 10)\n",
      "Reframed Shape:  (48, 10)\n",
      "Reframed Shape:  (52, 10)\n",
      "Reframed Shape:  (48, 10)\n",
      "Reframed Shape:  (52, 10)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2018)\n",
    "for country in [\"Mexico\", \"Brazil\", \"Colombia\"]:\n",
    "    folder = \"../../data/{}/processed_data\".format(country)\n",
    "    files = os.listdir(folder)\n",
    "    for file in files:\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            dataset = pd.read_csv(\"{}/{}\".format(folder, file), index_col=0)\n",
    "            state = file\n",
    "            formattedFilename = formatFilename(file)\n",
    "            \n",
    "            if(not os.path.isdir(\"{}/{}\".format(country, file))):\n",
    "                os.mkdir(\"{}/{}\".format(country, file))\n",
    "\n",
    "            train = dataset[:52]\n",
    "            test = dataset[48:] # Keep 4 previous values to be able to predict all 52 weeks of next year\n",
    "            x, y = getXY(train, population[file])\n",
    "            test_x, test_y = getXY(test, population[file])\n",
    "            model = createModel(file)\n",
    "            model.fit(x, y,\n",
    "                    epochs = 50,\n",
    "                    batch_size=x.shape[0],\n",
    "                    verbose=0, \n",
    "                    shuffle=False,\n",
    "                    validation_data=(test_x,test_y)\n",
    "                     )\n",
    "\n",
    "            \n",
    "            predictions = model.predict(test_x)\n",
    "            #Transform to 1-D\n",
    "            test_y = test_y.reshape((len(test_y), 1))\n",
    "\n",
    "            #Rescale\n",
    "            inv_yPred = np.apply_along_axis(lambda x: x * population[file] / 100000, 1, predictions)\n",
    "            inv_y = np.apply_along_axis(lambda x: x * population[file] / 100000, 1, test_y)\n",
    "\n",
    "            test = test[4:] # drop the first 4 values used previously to be able to predict the full year\n",
    "            test.drop([\"Searches\"], axis=1, inplace=True)\n",
    "            test.drop([\"Cases\"], axis=1, inplace=True)\n",
    "            test[\"Observed\"] = inv_y\n",
    "            test[\"Predicted\"] = inv_yPred\n",
    "            test[\"error\"] = test[\"Predicted\"] - test[\"Observed\"]\n",
    "            test.to_csv(\"{}/{}/{}\".format(country, file, file))\n",
    "            \n",
    "            colors = ['#2962FF', '#212121']\n",
    "            test[[\"Observed\", \"Predicted\"]].plot(figsize=(10,10), color=colors)\n",
    "            plt.title(\"LSTM Model\\n{}\".format(formattedFilename))\n",
    "            plt.xlabel(\"Date\")\n",
    "            plt.ylabel(\"ZIKV Cases\")\n",
    "            ax = plt.gca()\n",
    "            ax.set_facecolor((0.9, 0.9, 0.9, 0.7))\n",
    "            plt.legend()\n",
    "            plt.grid(linestyle='dashed', linewidth=1.5)\n",
    "            fig = plt.gcf()\n",
    "            fig.savefig(\"{}/{}/{}.png\".format(country, file, formattedFilename))\n",
    "            plt.grid()\n",
    "            plt.close(\"all\")\n",
    "            \n",
    "            test[[\"error\"]].plot(figsize=(10,10))\n",
    "            plt.title(\"LSTM Model Error\\n{}\".format(formattedFilename))\n",
    "            plt.xlabel(\"Date\")\n",
    "            plt.ylabel(\"LSTM Error\")\n",
    "            ax = plt.gca()\n",
    "            ax.set_facecolor((0.9, 0.9, 0.9, 0.7))\n",
    "            plt.legend()\n",
    "            plt.grid(linestyle='dashed', linewidth=1.5)\n",
    "            fig = plt.gcf()\n",
    "            fig.savefig(\"{}/{}/Error-{}.png\".format(country, file, formattedFilename))\n",
    "            plt.close(\"all\")\n",
    "\n",
    "            saveModel(model, \"{}/{}/Model\".format(country, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
