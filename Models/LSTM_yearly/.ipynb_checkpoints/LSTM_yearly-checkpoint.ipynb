{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from keras import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Dense, Concatenate, Flatten, Input\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import logcosh\n",
    "import tensorflow as tf\n",
    "from keras.constraints import non_neg\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Population values\n",
    "population = {\n",
    "    \"Chiapas_2016-2017.csv\": 5217908,\n",
    "    \"Colima_2016-2017.csv\": 711235,\n",
    "    \"Guerrero_2016-2017.csv\": 3533251,\n",
    "    \"Hidalgo_2016-2017.csv\": 2858359,\n",
    "    \"NuevoLeon_2016-2017.csv\": 5119504,\n",
    "    \"Oaxaca_2016-2017.csv\": 3967889,\n",
    "    \"QuintanaRoo_2016-2017.csv\": 1501562,\n",
    "    \"Tabasco_2016-2017.csv\" : 2395272,\n",
    "    \"Veracruz_2016-2017.csv\" : 8112505,\n",
    "    \"Yucatan_2016-2017.csv\" : 2097175,\n",
    "    \n",
    "    \"casanare_2016-2017.csv\" : 356438,\n",
    "    \"cordoba_2016-2017.csv\" : 1709603,\n",
    "    \"cundinamarca_2016-2017.csv\" : 2680041,\n",
    "    \"huila_2016-2017.csv\" : 1154804,\n",
    "    \"meta_2016-2017.csv\" : 961292,\n",
    "    \"santander_2016-2017.csv\" : 2061095,\n",
    "    \"santander_norte_2016-2017.csv\" : 1355723,\n",
    "    \"tolima_2016-2017.csv\" : 1408274,\n",
    "    \"valle_cauca_2016-2017.csv\" : 4613377,\n",
    "    \n",
    "    \"Alagoas_2016-2017.csv\": 3375823,\n",
    "    \"Bahia_2016-2017.csv\": 15344447,\n",
    "    \"Ceara_2016-2017.csv\": 9020460,\n",
    "    \"Goias_2016-2017.csv\": 6778772,\n",
    "    \"Maranhao_2016-2017.csv\": 7000229,\n",
    "    \"MatoGrosso_2016-2017.csv\": 3344544,\n",
    "    \"MinasGerais_2016-2017.csv\": 21119536,\n",
    "    \"Para_2016-2017.csv\": 8366628,\n",
    "    \"RioDeJaneiro_2016-2017.csv\": 16718956,\n",
    "    \"SaoPaulo_2016-2017.csv\": 45094866,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getXY(dataset, scale):\n",
    "    dataset[[\"Searches\"]] /= 100\n",
    "    dataset[[\"Cases\"]] = dataset[[\"Cases\"]].apply(lambda x: x*100000/scale, axis=1)\n",
    "    \n",
    "    values = dataset.values.astype(\"float32\")\n",
    "    \n",
    "    n_weeks = 4\n",
    "    n_features = 2\n",
    "\n",
    "    reframed = series_to_supervised(values, n_weeks, 1)\n",
    "    values = reframed.values\n",
    "    print(\"Reframed Shape: \", reframed.shape)\n",
    "    totalFeatures = reframed.shape[1]\n",
    "    n_obs = n_weeks * n_features\n",
    "\n",
    "    x,y = values[:, :8], values[:, -1] # Pick 4 previous weeks and predict 4 week ahead \n",
    "\n",
    "    x = x.reshape((x.shape[0], n_weeks, n_features)) # Reshape as 3-D\n",
    "    return x, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def saveModel(model, modelName):\n",
    "    jsonName = \"{}.json\".format(modelName)\n",
    "    h5Name = \"{}.h5\".format(modelName)\n",
    "\n",
    "    model_json = model.to_json()\n",
    "    with open(jsonName, \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    #seralize weights to HDF5\n",
    "    model.save_weights(h5Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "countryUnits = {\n",
    "    \"Brazil\": [\n",
    "        32,\n",
    "        16,\n",
    "        8,\n",
    "        8\n",
    "    ],\n",
    "    \"Colombia\": [\n",
    "        64,\n",
    "        64,\n",
    "        8,\n",
    "        2\n",
    "    ],\n",
    "    #BEST\n",
    "    \"Mexico\" : [\n",
    "        32,\n",
    "        64,\n",
    "        16,\n",
    "        8\n",
    "    ]\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "def createModel(country):\n",
    "    lstm, dense1, dense2, dense3 = countryUnits[country]\n",
    "    \n",
    "    input_layer = Input(shape=(4,2))\n",
    "    b1_out = LSTM(lstm, return_sequences=False)(input_layer)\n",
    "    \n",
    "    b2_out = Dense(dense1, activation=\"relu\", kernel_regularizer=\"l2\")(input_layer)\n",
    "    b2_out = Flatten()(b2_out)\n",
    "    \n",
    "    concatenated = concatenate([b1_out, b2_out])\n",
    "    out = Dense(dense2, activation=\"relu\", kernel_regularizer=\"l2\")(concatenated)\n",
    "    out = Dense(dense3, activation=\"relu\", kernel_regularizer=\"l2\")(out)\n",
    "    out = Dense(1, activation=\"linear\", kernel_constraint=non_neg(), name='output_layer')(out)\n",
    "    \n",
    "    model = Model([input_layer], out)\n",
    "    model.compile(loss=[\"mae\"], optimizer=\"adam\", metrics=[\"mae\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def formatFilename(filename):\n",
    "    return filename.replace(\".csv\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Aplicaciones\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:2352: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reframed Shape:  (48, 10)\n",
      "Reframed Shape:  (52, 10)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3218 - mean_absolute_error: 0.0037\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3175 - mean_absolute_error: 0.0036\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3129 - mean_absolute_error: 0.0032\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3082 - mean_absolute_error: 0.0025\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3033 - mean_absolute_error: 0.0018\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2984 - mean_absolute_error: 8.5824e-04\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2936 - mean_absolute_error: 9.9612e-05\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2903 - mean_absolute_error: 7.6078e-04\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2867 - mean_absolute_error: 0.0010\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2829 - mean_absolute_error: 0.0012\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2789 - mean_absolute_error: 0.0011\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2849 - mean_absolute_error: 0.0109\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2963 - mean_absolute_error: 0.0259\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2891 - mean_absolute_error: 0.0222\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2644 - mean_absolute_error: 9.3167e-04\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2614 - mean_absolute_error: 0.0013\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2582 - mean_absolute_error: 0.0015\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2549 - mean_absolute_error: 0.0016\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2514 - mean_absolute_error: 0.0014\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2479 - mean_absolute_error: 0.0011\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2444 - mean_absolute_error: 7.2470e-04\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2407 - mean_absolute_error: 2.1301e-04\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2378 - mean_absolute_error: 3.9565e-04\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2352 - mean_absolute_error: 7.9233e-04\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2324 - mean_absolute_error: 9.9117e-04\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2294 - mean_absolute_error: 0.0010\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2264 - mean_absolute_error: 9.0182e-04\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2233 - mean_absolute_error: 6.5923e-04\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2201 - mean_absolute_error: 3.0235e-04\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2746 - mean_absolute_error: 0.0577\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2146 - mean_absolute_error: 4.3167e-04\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2504 - mean_absolute_error: 0.0389\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2093 - mean_absolute_error: 4.9292e-04\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2065 - mean_absolute_error: 3.1816e-04\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2036 - mean_absolute_error: 2.6690e-05\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2014 - mean_absolute_error: 3.6626e-04\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1991 - mean_absolute_error: 5.8695e-04\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1966 - mean_absolute_error: 6.4932e-04\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1941 - mean_absolute_error: 5.7416e-04\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1915 - mean_absolute_error: 3.7727e-04\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1888 - mean_absolute_error: 7.1290e-05\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1868 - mean_absolute_error: 3.3175e-04\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1847 - mean_absolute_error: 5.6587e-04\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1825 - mean_absolute_error: 6.4693e-04\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1802 - mean_absolute_error: 5.9183e-04\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1779 - mean_absolute_error: 4.1452e-04\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1754 - mean_absolute_error: 1.2983e-04\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1734 - mean_absolute_error: 2.5398e-04\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1715 - mean_absolute_error: 4.7005e-04\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1696 - mean_absolute_error: 5.3872e-04\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1675 - mean_absolute_error: 4.7531e-04\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1653 - mean_absolute_error: 2.9423e-04\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 3 is out of bounds for array of dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-23f386440078>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0minv_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_along_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m100000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minv_yPred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# drop the first 4 values used previously to be able to predict the full year\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Aplicaciones\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36msqueeze\u001b[1;34m(a, axis)\u001b[0m\n\u001b[0;32m   1196\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1197\u001b[0m         \u001b[1;31m# First try to use the new axis= parameter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1198\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1199\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1200\u001b[0m         \u001b[1;31m# For backwards compatibility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 3 is out of bounds for array of dimension 3"
     ]
    }
   ],
   "source": [
    "np.random.seed(2018)\n",
    "for country in [\"Mexico\", \"Brazil\", \"Colombia\"]:\n",
    "    folder = \"../../data/{}/processed_data\".format(country)\n",
    "    files = os.listdir(folder)\n",
    "    for file in files:\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            dataset = pd.read_csv(\"{}/{}\".format(folder, file), index_col=0)\n",
    "            state = file\n",
    "            formattedFilename = formatFilename(file)\n",
    "            \n",
    "            if(not os.path.isdir(\"{}/{}\".format(country, file))):\n",
    "                os.mkdir(\"{}/{}\".format(country, file))\n",
    "\n",
    "            train = dataset[:52]\n",
    "            test = dataset[48:] # Keep 4 previous values to be able to predict all 52 weeks of next year\n",
    "            x, y = getXY(train, population[file])\n",
    "            \n",
    "            test_x, test_y = getXY(test, population[file])\n",
    "            model = createModel(country)\n",
    "            model.fit(x, y,\n",
    "                    epochs = 30,\n",
    "                    batch_size=x.shape[0],\n",
    "                    verbose=0, \n",
    "                    shuffle=False\n",
    "                     )\n",
    "            \n",
    "            predictions = []\n",
    "            for i in range(len(test_x)):\n",
    "                xShape = test_x[i].shape\n",
    "                x = np.expand_dims(test_x[i], axis=0)\n",
    "                y = np.zeros((1,), dtype=float)\n",
    "                y[0] = np.array(test_y[i])\n",
    "                predictions.append(model.predict(x))\n",
    "                model.fit(x, y)\n",
    "            \n",
    "            \n",
    "#             predictions = model.predict(test_x)\n",
    "            #Transform to 1-D\n",
    "            test_y = test_y.reshape((len(test_y), 1))\n",
    "    \n",
    "            #Rescale\n",
    "            inv_yPred = np.apply_along_axis(lambda x: x * population[file] / 100000, 1, predictions)\n",
    "            inv_y = np.apply_along_axis(lambda x: x * population[file] / 100000, 1, test_y)\n",
    "            \n",
    "            np.squeeze(inv_yPred, axis=2)\n",
    "            \n",
    "            test = test[4:] # drop the first 4 values used previously to be able to predict the full year\n",
    "            test.drop([\"Searches\"], axis=1, inplace=True)\n",
    "            test.drop([\"Cases\"], axis=1, inplace=True)\n",
    "            test[\"Observed\"] = inv_y\n",
    "            test[\"Predicted\"] = inv_yPred\n",
    "            test[\"error\"] = test[\"Predicted\"] - test[\"Observed\"]\n",
    "            test.to_csv(\"{}/{}/{}\".format(country, file, file))\n",
    "            \n",
    "            colors = ['#2962FF', '#212121']\n",
    "            test[[\"Observed\", \"Predicted\"]].plot(figsize=(10,10), color=colors)\n",
    "            plt.title(\"LSTM Model\\n{}\".format(formattedFilename))\n",
    "            plt.xlabel(\"Date\")\n",
    "            plt.ylabel(\"ZIKV Cases\")\n",
    "            ax = plt.gca()\n",
    "            ax.set_facecolor((0.9, 0.9, 0.9, 0.7))\n",
    "            plt.legend()\n",
    "            plt.grid(linestyle='dashed', linewidth=1.5)\n",
    "            fig = plt.gcf()\n",
    "            fig.savefig(\"{}/{}/{}.png\".format(country, file, formattedFilename))\n",
    "            plt.grid()\n",
    "            plt.close(\"all\")\n",
    "            \n",
    "            test[[\"error\"]].plot(figsize=(10,10))\n",
    "            plt.title(\"LSTM Model Error\\n{}\".format(formattedFilename))\n",
    "            plt.xlabel(\"Date\")\n",
    "            plt.ylabel(\"LSTM Error\")\n",
    "            ax = plt.gca()\n",
    "            ax.set_facecolor((0.9, 0.9, 0.9, 0.7))\n",
    "            plt.legend()\n",
    "            plt.grid(linestyle='dashed', linewidth=1.5)\n",
    "            fig = plt.gcf()\n",
    "            fig.savefig(\"{}/{}/Error-{}.png\".format(country, file, formattedFilename))\n",
    "            plt.close(\"all\")\n",
    "\n",
    "            saveModel(model, \"{}/{}/Model\".format(country, file))\n",
    "\n",
    "# Sound to alert me that the experiment has finished\n",
    "import winsound\n",
    "frequency = 2500  # Set Frequency To 2500 Hertz\n",
    "duration = 1000  # Set Duration To 1000 ms == 1 second\n",
    "winsound.Beep(frequency, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
